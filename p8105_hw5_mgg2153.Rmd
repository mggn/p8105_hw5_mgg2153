---
title: "p8105_hw5_mgg2153"
author: "mggn"
date: "11/16/2020"
output: github_document
---

```{r setup, message = FALSE}
library(tidyverse)
library(patchwork)
```

## Problem 1, as discussed in the live session from 11/10/2020

Read in the data.

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


```{r, error = TRUE}
city_prop_test = function(df) {
  
 # n_unsovled ...
  #n_total ... 
  
  prop.test(.....)
  
}
homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```


## Problem 2: Data from a longitudinal study

First, I'll start by creating a dataframe using the list.files command and then turning it
into a dataframe using tibble::enframe :

```{r list_files_tibble}
goal_spaghetti = 
list.files(path = "./hw5_data", full.names=FALSE)%>%
  tibble::enframe(name = NULL)
```

Now that has created a sort of shell for the data. I called it "goal_spaghetti" because at the 
end of this question, we are making a spaghetti plot. The next step is to read in the data, iterating
over the separate csv files to create a dataframe. After mapping the data I unnested, created variables
"arm" and "participant_id," and then pivoted longer to create a tidy dataset for plotting:

```{r message = FALSE}
goal_spaghetti_df =
  goal_spaghetti %>%
  mutate(
    data = map(value, ~read_csv(str_c("./hw5_data/", .x)))
  ) %>%
  unnest(cols = data) %>%
  separate(value, into=c("arm", "participant_id"))%>%
  mutate(participant_id = str_replace(participant_id, ".csv", ""))%>%
  pivot_longer(
   week_1:week_8,
   names_to = "week",
   names_prefix = "week_", 
   values_to = "obs_value"
  )
 
```

### Now we get to the goal of this problem: spaghetti! (plots)

```{r}
goal_spaghetti_df %>%
  mutate(
    arm = recode(arm,
      con = "Control",
      exp = "Experimental"
    )
  ) %>%
  ggplot(aes(x = week, y = obs_value, group = participant_id, color = participant_id))+
  geom_point()+
  geom_path()+
  labs(
   x = "Week number",
   y = "Observation value",
   title = "Observations on each subject over time by treatment arm",
   caption = "Spaghetti plot"
  )+
  facet_grid(.~arm)+
  theme_bw()+
  theme(plot.title = element_text(size = 11))

```


I used facet grid in the plot to separate participants by treatment arm with the goal of improving
graph readability. It looks like the control group has relatively "stable" measures, versus the experimental group 
seems so have a trend that is increasing over time. Whatever the experimental arm is, it seems to be having
an effect on the observation that positvely increases over the study span.

## Problem 3: Simulation exploring power in a one sample t-test

The goal here is to create a function where sample size, n, is fixed as 30; mean,
represented as mu, is the input, and sigma, the standard deviation, is fixed at 5.

```{r}
set.seed(1)

sim_power = function(n = 30, mu, sigma = 5) { #this line fixes the values of n and sigma
  
  sim_data = tibble(
    x = rnorm(n = n, mean = mu, sd = sigma) #define x as sampling from a normal dist
  )
  
  sim_data %>% #in this portion of the function, we are getting estimated means and sds
    summarize(
      mu = mean(x),
      sigma = sd(x)
    )
  
 
    sim_data %>% #and here we are creating a tidy table of the outputs of interest
      t.test() %>%
      broom::tidy() %>% 
      select(estimate, p.value)

}
```

Great, we have a function. I'd like to take a moment here to thank David J. Malan
for discussing functions in C. Functions in c are the worst but has made this process
slightly more straightforward.

In the next chunk, we run 5000 simulations of the function, sim_power, that was specified above:

```{r}

output = rerun(5000, sim_power(30, 0, 5)) %>%
  bind_rows()

head(output)
```

That worked-- so let's repeat it for imputs of mu ranging from 0-6

```{r}
#repeat for mu = 1-6

sim_results = 
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  )%>%
  mutate(
    output_list = map(.x = mu, ~rerun(5000, sim_power(mu = .x))),
    output_df = map(output_list, bind_rows)
  )%>%
  unnest(output_df) %>%
  select(-output_list)

head(sim_results)
  
```
Great-- that also worked. Of note: "p.value" variable name isn't in proper form,
so in the next code chunk we will janitor::clean_names, and... 

### create the plot of mu (population value) and power

P-value is restricted to where it is less than 0.05
because at an alpha of 0.05, a p-value of less than 0.05 is when the null is rejected:

```{r}
reject_plot =
  sim_results %>%
  group_by(mu) %>%
  count(p.value < 0.05)%>%
  mutate(
    power = n/sum(n)
  )%>%
  janitor::clean_names()%>% #p_value becomes p_value_0_05 and is boolean
  filter(p_value_0_05 == TRUE) %>%
  ggplot(aes(x = mu, y = power))+
  geom_point(color = "blue")+
  geom_smooth(alpha = .5, se = FALSE)+
  theme_bw()+
  labs(
    title = "μ vs. power",
    x = "μ",
    y = "power"
  )

```

The plot is logarithmic, and flattens out at power value of 1. This makes sense, because
power is the conditional probability:

**P(reject the null|the null is false)**

And probabilities range from 0-1. Additionally, we can see that as μ increases, so does power.
Holding all else constant (ie, fixing sample size), we can see that as the effect size increases,
so does power. They have a direct relationship.


#### Next: plot of average estimate of mu hat and true value of mu (just code)

```{r}
#for the entire dataset
avg_all_data = 
sim_results %>%
  group_by(mu)%>%
  summarize(mean_mu_hat = mean(estimate))%>% #take mean of estimated mu
  ggplot(aes(x = mu, y = mean_mu_hat))+
  geom_point()+
  geom_line(color = "blue")+
  theme_bw()+
    labs(
    title = "μ vs. average of μ(hat)",
    x = "true value of μ",
    y =  "average estimate of μ(hat)"
  )

```

#### Similar plot, but where the null was rejected (just code)

```{r}
 
avg_reject_data =
sim_results %>%
  janitor::clean_names()%>% #p value become p_value
  filter(p_value < 0.05) %>%
  group_by(mu) %>%
  summarize(mean_mu_hat_reject = mean(estimate)) %>%
  ggplot(aes(x = mu, y = mean_mu_hat_reject))+
  geom_point()+
  geom_line(se = FALSE)+
  theme_bw()+
  labs(
    title = "μ vs. average μ(hat), null rejected",
    x = "true value of μ",
    y =  "average estimate of μ(hat)"
  )


```

### both plots together

```{r}
avg_reject_data+avg_all_data

```

##### *Is the sample average of μ^ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?*
Among the tests for which the null was rejected, the true value of μ approximates the estimated mean value of μ(hat). As effect size increases,
power increases, and from the first plot of power we saw that the effect size was greatest at μ = 6. Essentially this plot demonstrates that when
a study is well-powered, the estimated μ will approach the true population μ. In statistics, we are trying to estimate population parameter values
as efficiently/as well as possible

 
 
